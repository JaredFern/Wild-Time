{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildtime import baseline_trainer, dataloader\n",
    "from wildtime.configs.eval_fix import configs_fmow as configs\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_params = {\n",
    "    'device': 0,\n",
    "    'random_seed': 1,\n",
    "    'num_workers': 8,\n",
    "    'mini_batch_size': 64,\n",
    "    'eval_batch_size': 512,\n",
    "    'ssl_finetune_iter': 1500,\n",
    "    'linear_probe_iter': 0,\n",
    "    'train_update_iter': 3000,\n",
    "\n",
    "    'eval_fix': True,\n",
    "    'difficulty': False,\n",
    "    'linear_probe': False,\n",
    "    'online': False,\n",
    "    'split_time': 13,\n",
    "    'eval_next_timestamps': 6,\n",
    "    'eval_all_timestamps': False,\n",
    "\n",
    "    'load_model': False,\n",
    "    'torch_compile': False,\n",
    "    'time_conditioned': False,\n",
    "    'swa_ewa': False,\n",
    "    'swa_steps': 500,\n",
    "\n",
    "    'data_dir': '/scratch/jaredfer/wilds/data/',\n",
    "    'log_dir': './checkpoints',\n",
    "    'checkpoint_path': '',\n",
    "    'results_dir': './results'\n",
    "}\n",
    "\n",
    "config = {**configs.configs_fmow_erm, **experimental_params}\n",
    "\n",
    "experimental_config = argparse.Namespace(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(K=1, buffer_size=100, checkpoint_path='', coral_lambda=1.0, cut_mix=False, data_dir='/scratch/jaredfer/wilds/data/', dataset='fmow', device=0, difficulty=False, emp_FI=False, epsilon=0.001, eval_all_timestamps=False, eval_batch_size=512, eval_fix=True, eval_next_timestamps=6, ewc_lambda=1.0, fisher_n=None, gamma=1.0, group_size=3, irm_lambda=1.0, irm_penalty_anneal_iters=0, linear_probe=False, linear_probe_iter=0, lisa=False, lisa_intra_domain=False, lisa_start_time=0, load_model=False, log_dir='./checkpoints', lr=0.0001, method='erm', mini_batch_size=64, mix_alpha=2.0, mixup=False, momentum=0.9, non_overlapping=False, num_groups=3, num_workers=8, online=False, prediction_type=None, random_seed=1, reduced_train_prop=None, regression=False, results_dir='./results', si_c=0.1, split_time=13, ssl_finetune_iter=1500, swa_ewa=False, swa_steps=500, time_conditioned=False, torch_compile=False, train_update_iter=3000, weight_decay=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Running Eval-Fix...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m baseline_trainer\u001b[39m.\u001b[39;49mtrain(experimental_config)\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/baseline_trainer.py:149\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(args):\n\u001b[1;32m    148\u001b[0m     trainer \u001b[39m=\u001b[39m init(args)\n\u001b[0;32m--> 149\u001b[0m     trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/methods/base_trainer.py:316\u001b[0m, in \u001b[0;36mBaseTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_task_difficulty()\n\u001b[1;32m    315\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_fix:\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_eval_fix()\n\u001b[1;32m    317\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eval_stream()\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/methods/base_trainer.py:264\u001b[0m, in \u001b[0;36mBaseTrainer.run_eval_fix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_online()\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_offline()\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_all_timestamps:\n\u001b[1;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_offline_all_timestamps()\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/methods/base_trainer.py:129\u001b[0m, in \u001b[0;36mBaseTrainer.train_offline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model(timestamp)\n\u001b[1;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(train_id_dataloader)\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(timestamp)\n\u001b[1;32m    131\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/methods/base_trainer.py:77\u001b[0m, in \u001b[0;36mBaseTrainer.train_step\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m step, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     76\u001b[0m     x, y \u001b[39m=\u001b[39m prepare_data(x, y, \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset))\n\u001b[0;32m---> 77\u001b[0m     loss, logits, y \u001b[39m=\u001b[39m forward_pass(x, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataset, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlisa, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmixup,\n\u001b[1;32m     78\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcut_mix, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmix_alpha)\n\u001b[1;32m     79\u001b[0m     loss_all\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/methods/utils.py:84\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(x, y, dataset, network, criterion, use_lisa, use_mixup, cut_mix, mix_alpha)\u001b[0m\n\u001b[1;32m     81\u001b[0m     loss \u001b[39m=\u001b[39m mixup_criterion(criterion, logits, y_a, y_b, lam)\n\u001b[1;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     logits \u001b[39m=\u001b[39m network(x)\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(dataset) \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mdrug\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     86\u001b[0m         logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mdouble()\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Year3/Wild-Time/wildtime/networks/fmow.py:35\u001b[0m, in \u001b[0;36mFMoWNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 35\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc(x)\n\u001b[1;32m     36\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(features, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool2d(out, (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[39m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m name, layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[39m=\u001b[39m layer(features)\n\u001b[1;32m    123\u001b[0m     features\u001b[39m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(features, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torchvision/models/densenet.py:90\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     bottleneck_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 90\u001b[0m new_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_rate \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     92\u001b[0m     new_features \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(new_features, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_rate, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_trainer.train(experimental_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild-time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
