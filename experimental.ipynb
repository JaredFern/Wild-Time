{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`fused_weight_gradient_mlp_cuda` module not found. gradient accumulation fusion with weight gradient computation disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from importlib import reload\n",
    "\n",
    "from analysis import forgetting\n",
    "\n",
    "from wildtime import baseline_trainer, dataloader\n",
    "from wildtime.configs.eval_fix import (\n",
    "    configs_mimic_mortality, configs_mimic_readmission, \n",
    "    configs_fmow, configs_arxiv, configs_huffpost, configs_yearbook\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'analysis.forgetting' from '/home/jaredfer/Projects/distshift/Wild-Time/analysis/forgetting.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(forgetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"/data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results\"\n",
    "\n",
    "EXP_PATHS =  \n",
    "    ('fmow', 'cs'): \"0504_fmow_swa_coldstart_csaw\",\n",
    "    ('fmow', 'ws'): \"0504_fmow_swa_csaw_lambda0.75\", \n",
    "    ('huffpost', 'cs'): \"0504_huffpost_swa_coldstart_csaw\",\n",
    "    ('huffpost', 'ws'): \"0504_huffpost_swa_warmstart_csaw_2\",\n",
    "    ('arxiv', 'cs'): \"0509_arxiv_swa_coldstart_csaw_seed_1\" ,\n",
    "    ('arxiv', 'ws'): \"0509_arxiv_swa_warmstart_csaw_seed_1\",\n",
    "    ('yearbook', 'cs'): \"0504_yearbook_swa_coldstart_csaw\",\n",
    "    ('yearbook', 'ws'): \"0504_yearbook_swa_csaw_lambda0.75\",\n",
    "}\n",
    "\n",
    "OPTIMAL_DECAY = {\n",
    "    ('fmow', 'cs'): 0.90,\n",
    "    ('fmow', 'ws'): 0.75, \n",
    "    ('huffpost', 'cs'): 0.85,\n",
    "    ('huffpost', 'ws'): 0.45,\n",
    "    ('arxiv', 'cs'): 0.75,\n",
    "    ('arxiv', 'ws'): 0.50,\n",
    "    ('yearbook', 'cs'): 0.90,\n",
    "    ('yearbook', 'ws'): 0.75,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PARAMS = {\n",
    "    'dataset': \"huffpost\",\n",
    "    'method': 'swa',\n",
    "    'eval_batch_size': 2048,\n",
    "    'swa_ewa_lambda': 0.50,\n",
    "    'exp_path': '0124_huffpost_agem_agem_0',\n",
    "\n",
    "    'device': 0,\n",
    "    'random_seed': 1,\n",
    "    'num_workers': 0,\n",
    "\n",
    "    'eval_fix': True,\n",
    "    'eval_warmstart_finetune': False,\n",
    "    'eval_features': False,\n",
    "    'linear_probe': False,\n",
    "    'online': False,\n",
    "    'offline_steps': 1000,\n",
    "    'online_steps': 1000,\n",
    "\n",
    "    'eval_all_timestamps': False,\n",
    "\n",
    "    'load_model': False,\n",
    "    'torch_compile': False,\n",
    "    'sam': False,\n",
    "    'swa_ewa': True,\n",
    "    'swa_steps': None,\n",
    "    'swa_load_from_checkpoint': True,\n",
    "\n",
    "    'data_dir': '/data/tir/projects/tir6/strubell/data/wilds/data',\n",
    "    'log_dir': '/data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results',\n",
    "    'results_dir': '/data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem',\n",
    "    'checkpoint_path': ''\n",
    "\n",
    "    # 'checkpoint_path': '/data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/0509_arxiv_swa_warmstart_csaw_seed_1/time_2016'\n",
    "}\n",
    "\n",
    "if EXP_PARAMS['dataset'] == 'fmow':\n",
    "    config =  {**configs_fmow.configs_fmow_erm, **EXP_PARAMS}\n",
    "    eval_checkpoints = [f\"time_{i}.pth\" for i in range(11)]\n",
    "if EXP_PARAMS['dataset'] == 'huffpost':\n",
    "    config =  {**configs_huffpost.configs_huffpost_erm, **EXP_PARAMS}\n",
    "    eval_checkpoints = [f\"time_{i}.pth\" for i in range(2012, 2016)]\n",
    "if EXP_PARAMS['dataset'] == 'arxiv':\n",
    "    eval_checkpoints = [f\"time_{i}.pth\" for i in range(2007, 2016)]\n",
    "    config = {**configs_arxiv.configs_arxiv_erm, **EXP_PARAMS}\n",
    "if EXP_PARAMS['dataset'] == 'yearbook':\n",
    "    eval_checkpoints = [f\"time_{i}.pth\" for i in range(1930, 1970)]\n",
    "    config = {**configs_yearbook.configs_yearbook_erm, **EXP_PARAMS}\n",
    "if EXP_PARAMS['dataset'] == 'mimic':\n",
    "    config = {**configs_mimic_mortality.configs_mimic_mortality_erm, **EXP_PARAMS}\n",
    "\n",
    "experimental_config = argparse.Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertFeaturizer: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertFeaturizer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertFeaturizer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trainer = baseline_trainer.init(experimental_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time_2012.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jaredfer/Projects/distshift/Wild-Time/experimental.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://localhost:8080/home/jaredfer/Projects/distshift/Wild-Time/experimental.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m eval_ckpts \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2012\u001b[39m, \u001b[39m2016\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://localhost:8080/home/jaredfer/Projects/distshift/Wild-Time/experimental.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m data_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(config[\u001b[39m'\u001b[39m\u001b[39mresults_dir\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mexp_path\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://localhost:8080/home/jaredfer/Projects/distshift/Wild-Time/experimental.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m _, pred_logits, labels \u001b[39m=\u001b[39m fm\u001b[39m.\u001b[39;49mget_predictions(trainer,  [\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtime_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m2012\u001b[39;49m, \u001b[39m2016\u001b[39;49m)], data_dir)\n",
      "File \u001b[0;32m~/Projects/distshift/Wild-Time/forgetting_main.py:69\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(trainer, checkpoints, checkpoint_dir, mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     trainer\u001b[39m.\u001b[39mload_model(checkpoint_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[0;32m---> 69\u001b[0m acc, pred, label \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun_eval_timestamp(split, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m     71\u001b[0m split_preds\u001b[39m.\u001b[39mappend(pred)\n\u001b[1;32m     72\u001b[0m split_labels\u001b[39m.\u001b[39mappend(label)\n",
      "File \u001b[0;32m~/Projects/distshift/Wild-Time/wildtime/methods/base_trainer.py:537\u001b[0m, in \u001b[0;36mBaseTrainer.run_eval_timestamp\u001b[0;34m(self, timestamp, mode)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset\u001b[39m.\u001b[39mupdate_current_timestamp(timestamp)\n\u001b[1;32m    531\u001b[0m test_ood_dataloader \u001b[39m=\u001b[39m FastDataLoader(\n\u001b[1;32m    532\u001b[0m     dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset,\n\u001b[1;32m    533\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_batch_size,\n\u001b[1;32m    534\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers,\n\u001b[1;32m    535\u001b[0m     collate_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_collate_fn\n\u001b[1;32m    536\u001b[0m )\n\u001b[0;32m--> 537\u001b[0m acc, preds, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork_evaluation(test_ood_dataloader, return_probs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    538\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    539\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOOD timestamp = \u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    540\u001b[0m \u001b[39mreturn\u001b[39;00m acc, preds, labels\n",
      "File \u001b[0;32m~/Projects/distshift/Wild-Time/wildtime/methods/base_trainer.py:250\u001b[0m, in \u001b[0;36mBaseTrainer.network_evaluation\u001b[0;34m(self, test_time_dataloader, return_probs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmethod \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mswa\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 250\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswa_model(x)\n\u001b[1;32m    251\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(x)\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/optim/swa_utils.py:117\u001b[0m, in \u001b[0;36mAveragedModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/distshift/Wild-Time/wildtime/networks/article.py:43\u001b[0m, in \u001b[0;36mArticleNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     42\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m---> 43\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier(features)\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/wild-time/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import forgetting_main as fm\n",
    "reload(fm)\n",
    "\n",
    "trainer.swa_ewa_lambda = 0.50\n",
    "\n",
    "eval_ckpts = [f\"time_{i}.pth\" for i in range(2012, 2016)]\n",
    "data_dir = os.path.join(config['results_dir'], config['exp_path'])\n",
    "_, pred_logits, labels = fm.get_predictions(trainer,  [f\"time_{i}.pth\" for i in range(2012, 2016)], data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2012.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2013.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2014.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2015.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2012.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2013.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0307,  0.0015,  0.0144, -0.0247,  0.0085,  0.0310, -0.0296, -0.0130,\n",
      "         0.0021, -0.0227,  0.0410], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2014.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0261,  0.0053,  0.0181, -0.0332,  0.0092,  0.0380, -0.0281, -0.0240,\n",
      "        -0.0007, -0.0314,  0.0486], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2015.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0210,  0.0056,  0.0234, -0.0370,  0.0105,  0.0389, -0.0277, -0.0350,\n",
      "         0.0029, -0.0379,  0.0570], device='cuda:0', requires_grad=True)\n",
      "\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2012.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2013.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0288,  0.0061,  0.0155, -0.0320,  0.0090,  0.0340, -0.0343, -0.0202,\n",
      "        -0.0039, -0.0268,  0.0467], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2014.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0216,  0.0092,  0.0217, -0.0417,  0.0100,  0.0451, -0.0267, -0.0351,\n",
      "        -0.0034, -0.0401,  0.0562], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2015.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0159,  0.0058,  0.0288, -0.0408,  0.0118,  0.0397, -0.0272, -0.0460,\n",
      "         0.0064, -0.0444,  0.0654], device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 0.5, 1]:\n",
    "    trainer.create_csaw_from_ckpts(0, lambda_val=i)\n",
    "    print()\n",
    "    # print(trainer.swa_model.module.classifier.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.create_csaw_from_ckpts(0, 1)\n",
    "trainer.swa_model.module.classifier.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2012.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0031,  0.0134, -0.0173,  0.0079,  0.0281, -0.0249, -0.0058,\n",
      "         0.0081, -0.0186,  0.0353], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2013.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0293,  0.0047,  0.0152, -0.0298,  0.0089,  0.0331, -0.0329, -0.0180,\n",
      "        -0.0021, -0.0255,  0.0450], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2014.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0227,  0.0085,  0.0207, -0.0399,  0.0098,  0.0433, -0.0276, -0.0325,\n",
      "        -0.0032, -0.0379,  0.0546], device='cuda:0', requires_grad=True)\n",
      "Updated model from /data/tir/projects/tir6/strubell/jaredfer/projects/wild-time/results/icml/huffpost/agem/0124_huffpost_agem_agem_0/checkpoints/time_2015.pth\n",
      "Parameter containing:\n",
      "tensor([ 0.0169,  0.0062,  0.0276, -0.0407,  0.0115,  0.0402, -0.0273, -0.0440,\n",
      "         0.0049, -0.0434,  0.0637], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 0.4044368600682594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 0.4510250569476082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 0.47680412371134023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.create_csaw_from_ckpts(0, 0.85)\n",
    "\n",
    "eval_splits = [t for t in trainer.eval_dataset.ENV if t > trainer.split_time]\n",
    "accs = []\n",
    "for t in eval_splits:\n",
    "   accs.append(trainer.run_eval_timestamp(t, 1)[0])\n",
    "   print(t, accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39334470989761094, 0.4419134396355353, 0.47164948453608246] 0.43563587802307624\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "print(accs, np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"arxiv\"\n",
    "init = \"ws\"\n",
    "\n",
    "EXP_DIR = EXP_PATHS[(dataset, init)]\n",
    "\n",
    "data_fpath = os.path.join(DATA_DIR, EXP_DIR, f'preds_meta_swa_{OPTIMAL_DECAY[(dataset, init)]}.pkl')\n",
    "data_swa = forgetting.load_predictions_and_metadata(data_fpath)\n",
    "\n",
    "\n",
    "data_fpath = os.path.join(DATA_DIR, EXP_DIR, 'preds_meta_swa_1.0.pkl')\n",
    "data = forgetting.load_predictions_and_metadata(data_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FT WS\n",
    "[_[-1].mean() for _ in corr], [_[-1].mean() for _ in corr_swa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_[-1].mean() for _ in corr], [_[-1].mean() for _ in corr_swa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[_, corr[-1][_].mean()] for _ in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5363446713363825\n",
      "0.5417760540236131\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([_[-1].mean() for _ in corr]))\n",
    "print(np.mean([_[-1].mean() for _ in corr_swa]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[False, False, False, ..., False, False,  True],\n",
       "        [False,  True, False, ...,  True, False, False],\n",
       "        [ True, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True, False, ..., False,  True, False],\n",
       "        [ True, False,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]),\n",
       " array([[ True,  True, False, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False,  True],\n",
       "        [False, False,  True, ..., False,  True,  True],\n",
       "        ...,\n",
       "        [False,  True, False, ...,  True,  True,  True],\n",
       "        [False,  True,  True, ..., False,  True,  True],\n",
       "        [False, False, False, ...,  True,  True, False]]),\n",
       " array([[False, False,  True, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False,  True],\n",
       "        [False,  True,  True, ..., False,  True,  True],\n",
       "        ...,\n",
       "        [ True, False,  True, ..., False, False,  True],\n",
       "        [False,  True, False, ..., False, False,  True],\n",
       "        [False,  True,  True, ..., False,  True,  True]]),\n",
       " array([[False,  True, False, ...,  True, False,  True],\n",
       "        [ True, False, False, ..., False, False,  True],\n",
       "        [ True, False, False, ..., False,  True, False],\n",
       "        ...,\n",
       "        [ True,  True, False, ...,  True,  True, False],\n",
       "        [ True,  True, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True, False]]),\n",
       " array([[False, False,  True, ...,  True, False, False],\n",
       "        [False, False, False, ...,  True, False,  True],\n",
       "        [False, False, False, ..., False, False,  True],\n",
       "        ...,\n",
       "        [ True, False,  True, ...,  True, False, False],\n",
       "        [False,  True,  True, ...,  True, False,  True],\n",
       "        [ True,  True, False, ...,  True, False, False]]),\n",
       " array([[False,  True, False, ..., False, False,  True],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [False,  True, False, ...,  True, False, False],\n",
       "        ...,\n",
       "        [False,  True,  True, ...,  True,  True, False],\n",
       "        [ True, False, False, ..., False,  True, False],\n",
       "        [ True,  True, False, ..., False,  True, False]])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval on 0\n",
      "Transferred [  97   75 -168  -17   -3   13   -2   19   19]\n",
      "Hard [-135 -158  220   49   24  -22    3  -18  -16]\n",
      "Learned [ 135  158 -220  -49  -24   22   -3   18   16]\n",
      "Forgotten [-97 -75 168  17   3 -13   2 -19 -19] \n",
      "\n",
      "Eval on 1\n",
      "Transferred [  94   95 -159  -32  -19    4   -1   35   54]\n",
      "Hard [-200 -173  255   77    6    2   21   -9  -15]\n",
      "Learned [ 200  173 -255  -77   -6   -2  -21    9   15]\n",
      "Forgotten [-94 -95 159  32  19  -4   1 -35 -54] \n",
      "\n",
      "Eval on 2\n",
      "Transferred [ 113  128 -201  -21    7   40   -9   24   69]\n",
      "Hard [-178 -246  277   53  -19    0   16  -59  -24]\n",
      "Learned [ 178  246 -277  -53   19    0  -16   59   24]\n",
      "Forgotten [-113 -128  201   21   -7  -40    9  -24  -69] \n",
      "\n",
      "Eval on 3\n",
      "Transferred [ 197  114 -144  -23   23   34  -32   37   71]\n",
      "Hard [-272 -260  324    1   11  -64   -7  -40  -40]\n",
      "Learned [ 272  260 -324   -1  -11   64    7   40   40]\n",
      "Forgotten [-197 -114  144   23  -23  -34   32  -37  -71] \n",
      "\n",
      "Eval on 4\n",
      "Transferred [ 253  182 -195  -68   17   80   13   36   71]\n",
      "Hard [-337 -331  301  -31  -44  -66   19  -74  -73]\n",
      "Learned [ 337  331 -301   31   44   66  -19   74   73]\n",
      "Forgotten [-253 -182  195   68  -17  -80  -13  -36  -71] \n",
      "\n",
      "Eval on 5\n",
      "Transferred [121  72 -70   4   7   1 -38  27  53]\n",
      "Hard [-128 -136  167   10  -29  -25  -29  -10  -11]\n",
      "Learned [ 128  136 -167  -10   29   25   29   10   11]\n",
      "Forgotten [-121  -72   70   -4   -7   -1   38  -27  -53] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "corr = forgetting.get_correctness(data)\n",
    "corr_swa = forgetting.get_correctness(data_swa)\n",
    "\n",
    "ft_events = forgetting.evaluate_method(corr, corr, diff_all=False)\n",
    "csaw_events = forgetting.evaluate_method(corr, corr_swa, diff_all=False)\n",
    "\n",
    "for t in range(len(ft_events[0])):\n",
    "    print(f\"Eval on {t}\")\n",
    "    print(\"Transferred\", np.array(csaw_events[0][t]) - np.array(ft_events[0][t]))\n",
    "    print(\"Hard\", np.array(csaw_events[1][t]) - np.array(ft_events[1][t]))\n",
    "    print(\"Learned\", np.array(csaw_events[2][t]) - np.array(ft_events[2][t]))\n",
    "    print(\"Forgotten\", np.array(csaw_events[3][t]) - np.array(ft_events[3][t]), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_nodes = construct_example_flow_graph(data_swa['transferred'][-1][6:], data_swa['hard'][-1][6:], data_swa['learned'][-1][6:], data_swa['forgotten'][-1][6:])\n",
    "source, target,value, node_labels, color, node_heights = convert_flow_graph_to_plotly(sankey_nodes)\n",
    "plot_sankey(source, target,value, node_labels, color, node_heights / max(node_heights), title=f\"CSAW: {data['model']}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_nodes = construct_example_flow_graph(data['transferred'][-1][6:], data['hard'][-1][6:], data['learned'][-1][6:], data['forgotten'][-1][6:])\n",
    "source, target,value, node_labels, color, node_heights = convert_flow_graph_to_plotly(sankey_nodes)\n",
    "plot_sankey(source, target,value, node_labels, color, node_heights / max(node_heights), title=f\"FT: {data['model']}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_nodes = construct_example_flow_graph(data['transferred'][-1][8:], data['hard'][-1][8:], data['learned'][-1][8:], data['forgotten'][-1][8:])\n",
    "source, target,value, node_labels, color, node_heights = convert_flow_graph_to_plotly(sankey_nodes)\n",
    "plot_sankey(source, target,value, node_labels, color, node_heights / max(node_heights), title=f\"Splits 11: {data['model']}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transferred, hard, learned, forgotten = find_learning_and_forgetting_events(np.hstack(labels), pred_labels=np.hstack(pred_labels))\n",
    "\n",
    "sankey_nodes = construct_example_flow_graph(transferred, hard, learned, forgotten)\n",
    "\n",
    "# source, target,value, labels, color, node_heights\n",
    "source, target,value, node_labels, color, node_heights = convert_flow_graph_to_plotly(\n",
    "    sankey_nodes, learned, forgotten\n",
    ")\n",
    "plot_sankey([], color, source, target, value, title=f\"All Eval Splits: {MODEL}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"Warmstart FT\"\n",
    "for split, label, pred_label in zip(eval_splits, labels, pred_labels):\n",
    "    transferred, hard, learned, forgotten = find_learning_and_forgetting_events(label, pred_labels=pred_label)\n",
    "\n",
    "    sankey_nodes = construct_example_flow_graph(transferred, hard, learned, forgotten)\n",
    "    source, target,value, node_labels, color, node_heights = convert_flow_graph_to_plotly(sankey_nodes)\n",
    "    plot_sankey([], color, source, target, value, title=f\"at time {split}: {MODEL}\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild-time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
